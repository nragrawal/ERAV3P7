model6.log

CUDA Available? True
/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(
Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)
cuda
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1            [-1, 8, 26, 26]              72
              ReLU-2            [-1, 8, 26, 26]               0
       BatchNorm2d-3            [-1, 8, 26, 26]              16
           Dropout-4            [-1, 8, 26, 26]               0
            Conv2d-5           [-1, 16, 24, 24]           1,152
              ReLU-6           [-1, 16, 24, 24]               0
       BatchNorm2d-7           [-1, 16, 24, 24]              32
           Dropout-8           [-1, 16, 24, 24]               0
            Conv2d-9           [-1, 10, 24, 24]             160
        MaxPool2d-10           [-1, 10, 12, 12]               0
           Conv2d-11           [-1, 10, 10, 10]             900
             ReLU-12           [-1, 10, 10, 10]               0
      BatchNorm2d-13           [-1, 10, 10, 10]              20
          Dropout-14           [-1, 10, 10, 10]               0
           Conv2d-15             [-1, 16, 8, 8]           1,440
             ReLU-16             [-1, 16, 8, 8]               0
      BatchNorm2d-17             [-1, 16, 8, 8]              32
          Dropout-18             [-1, 16, 8, 8]               0
           Conv2d-19             [-1, 16, 6, 6]           2,304
             ReLU-20             [-1, 16, 6, 6]               0
      BatchNorm2d-21             [-1, 16, 6, 6]              32
          Dropout-22             [-1, 16, 6, 6]               0
           Conv2d-23             [-1, 10, 6, 6]           1,440
        AvgPool2d-24             [-1, 10, 1, 1]               0
================================================================
Total params: 7,600
Trainable params: 7,600
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.00
Forward/backward pass size (MB): 0.58
Params size (MB): 0.03
Estimated Total Size (MB): 0.62
----------------------------------------------------------------
EPOCH: 0
Loss=0.09763453155755997 Batch_id=468 Accuracy=89.97: 100%|██████████| 469/469 [00:26<00:00, 17.83it/s]
Test set: Average loss: 0.0735, Accuracy: 9807/10000 (98.07%)

EPOCH: 1
Loss=0.09233377128839493 Batch_id=468 Accuracy=97.92: 100%|██████████| 469/469 [00:20<00:00, 22.59it/s]
Test set: Average loss: 0.0478, Accuracy: 9850/10000 (98.50%)

EPOCH: 2
Loss=0.028377527371048927 Batch_id=468 Accuracy=98.44: 100%|██████████| 469/469 [00:21<00:00, 22.23it/s]
Test set: Average loss: 0.0389, Accuracy: 9884/10000 (98.84%)

EPOCH: 3
Loss=0.01632087491452694 Batch_id=468 Accuracy=98.61: 100%|██████████| 469/469 [00:23<00:00, 20.35it/s]
Test set: Average loss: 0.0403, Accuracy: 9885/10000 (98.85%)

EPOCH: 4
Loss=0.01758650131523609 Batch_id=468 Accuracy=98.75: 100%|██████████| 469/469 [00:21<00:00, 21.70it/s]
Test set: Average loss: 0.0298, Accuracy: 9910/10000 (99.10%)

EPOCH: 5
Loss=0.05098794400691986 Batch_id=468 Accuracy=98.82: 100%|██████████| 469/469 [00:20<00:00, 22.41it/s]
Test set: Average loss: 0.0276, Accuracy: 9916/10000 (99.16%)

EPOCH: 6
Loss=0.06084083020687103 Batch_id=468 Accuracy=98.96: 100%|██████████| 469/469 [00:21<00:00, 21.45it/s]
Test set: Average loss: 0.0253, Accuracy: 9924/10000 (99.24%)

EPOCH: 7
Loss=0.04438317194581032 Batch_id=468 Accuracy=99.00: 100%|██████████| 469/469 [00:21<00:00, 21.86it/s]
Test set: Average loss: 0.0254, Accuracy: 9919/10000 (99.19%)

EPOCH: 8
Loss=0.016299666836857796 Batch_id=468 Accuracy=99.07: 100%|██████████| 469/469 [00:21<00:00, 22.18it/s]
Test set: Average loss: 0.0251, Accuracy: 9924/10000 (99.24%)

EPOCH: 9
Loss=0.011390108615159988 Batch_id=468 Accuracy=99.11: 100%|██████████| 469/469 [00:22<00:00, 20.62it/s]
Test set: Average loss: 0.0266, Accuracy: 9915/10000 (99.15%)

EPOCH: 10
Loss=0.008411864750087261 Batch_id=468 Accuracy=99.15: 100%|██████████| 469/469 [00:22<00:00, 20.44it/s]
Test set: Average loss: 0.0232, Accuracy: 9932/10000 (99.32%)

EPOCH: 11
Loss=0.0047716922126710415 Batch_id=468 Accuracy=99.16: 100%|██████████| 469/469 [00:21<00:00, 21.97it/s]
Test set: Average loss: 0.0257, Accuracy: 9919/10000 (99.19%)

EPOCH: 12
Loss=0.023506851866841316 Batch_id=468 Accuracy=99.21: 100%|██████████| 469/469 [00:20<00:00, 22.72it/s]
Test set: Average loss: 0.0265, Accuracy: 9912/10000 (99.12%)

EPOCH: 13
Loss=0.011653249152004719 Batch_id=468 Accuracy=99.23: 100%|██████████| 469/469 [00:22<00:00, 20.80it/s]
Test set: Average loss: 0.0223, Accuracy: 9932/10000 (99.32%)

EPOCH: 14
Loss=0.01652069017291069 Batch_id=468 Accuracy=99.28: 100%|██████████| 469/469 [00:22<00:00, 20.80it/s]
Test set: Average loss: 0.0216, Accuracy: 9933/10000 (99.33%)

EPOCH: 15
Loss=0.014461792074143887 Batch_id=468 Accuracy=99.24: 100%|██████████| 469/469 [00:21<00:00, 22.15it/s]
Test set: Average loss: 0.0234, Accuracy: 9924/10000 (99.24%)

EPOCH: 16
Loss=0.027581484988331795 Batch_id=468 Accuracy=99.29: 100%|██████████| 469/469 [00:21<00:00, 21.76it/s]
Test set: Average loss: 0.0212, Accuracy: 9931/10000 (99.31%)

EPOCH: 17
Loss=0.018696676939725876 Batch_id=468 Accuracy=99.37: 100%|██████████| 469/469 [00:22<00:00, 20.94it/s]
Test set: Average loss: 0.0207, Accuracy: 9933/10000 (99.33%)

EPOCH: 18
Loss=0.019025225192308426 Batch_id=468 Accuracy=99.38: 100%|██████████| 469/469 [00:21<00:00, 21.60it/s]
Test set: Average loss: 0.0199, Accuracy: 9938/10000 (99.38%)

EPOCH: 19
Loss=0.013096529059112072 Batch_id=468 Accuracy=99.33: 100%|██████████| 469/469 [00:21<00:00, 22.16it/s]
Test set: Average loss: 0.0216, Accuracy: 9935/10000 (99.35%)

